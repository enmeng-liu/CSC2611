{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg65 = ('cord', 'smile', 'rooster', 'voyage', 'noon', 'string', 'fruit', 'furnace', 'autograph', 'shore',\n",
    "     'automobile', 'wizard', 'mound' ,'stove', 'grin', 'implement', 'asylum', 'fruit', 'asylum', 'monk',\n",
    "     'graveyard', 'madhouse', 'glass', 'magician', 'boy', 'rooster', 'cushion','jewel', 'monk', 'slave',\n",
    "     'asylum', 'cemetery', 'coast', 'forest', 'grin', 'lad', 'shore', 'woodland', 'monk', 'oracle',\n",
    "     'boy', 'sage', 'automobile', 'cushion', 'mound', 'shore', 'lad', 'wizard', 'forest', 'graveyard',\n",
    "     'food', 'rooster', 'cemetery', 'woodland', 'shore', 'voyage', 'bird', 'woodland', 'coast', 'hill',\n",
    "     'furnace', 'implement', 'crane', 'rooster', 'hill', 'woodland', 'car', 'journey', 'cemetery', 'mound',\n",
    "     'glass', 'jewel', 'magician', 'oracle', 'crane', 'implement', 'brother', 'lad', 'sage', 'wizard',\n",
    "     'oracle', 'sage', 'bird', 'crane', 'bird', 'cock', 'food', 'fruit', 'brother', 'monk',\n",
    "     'asylum', 'madhouse', 'furnace', 'stove', 'magician', 'wizard', 'hill', 'mound', 'cord', 'string',\n",
    "     'glass', 'tumbler', 'grin', 'smile', 'serf', 'slave', 'journey', 'voyage', 'autograph', 'signature',\n",
    "     'coast', 'shore', 'forest', 'woodland', 'implement', 'tool', 'cock', 'rooster', 'boy', 'lad',\n",
    "     'cushion', 'pillow', 'cemetery', 'graveyard', 'automobile', 'car', 'midday', 'noon', 'gem', 'jewel')\n",
    "human_similarity = (0.02, 0.04, 0.04, 0.05, 0.06, 0.11, 0.14, 0.18, 0.19, 0.39,\n",
    "            0.42, 0.44, 0.44, 0.45, 0.57, 0.79, 0.85, 0.88, 0.90, 0.91,\n",
    "            0.96, 0.97, 0.97, 0.99, 1.00, 1.09, 1.18, 1.22, 1.24, 1.26,\n",
    "            1.37, 1.41, 1.48, 1.55, 1.69, 1.78, 1.82, 2.37, 2.41, 2.46,\n",
    "            2.61, 2.63, 2.63, 2.69, 2.74, 3.04, 3.11, 3.21, 3.29, 3.41,\n",
    "            3.45, 3.46, 3.46, 3.58, 3.59, 3.60, 3.65, 3.66, 3.68, 3.82,\n",
    "            3.84, 3.88, 3.92, 3.94, 3.94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Mengzelev\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 5000 most common English words (denoted by W) based on unigram frequencies in the Brown corpus\n",
    "fdist = nltk.FreqDist(w.lower() for w in brown.words())\n",
    "wfreq = fdist.most_common(5000)\n",
    "w = list(x[0] for x in wfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update W by adding rg65 words and make sure they are at 0-len\n",
    "rg65_set = set(rg65)\n",
    "for word in rg65_set:\n",
    "    if word not in w:\n",
    "        w.insert(0, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct bigram for the brown corpus\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "\n",
    "bigrams = ngrams(brown.words(), 2)\n",
    "bigrams_freq = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6288"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_freq[(',', 'and')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a word-context vector model (denoted by M1) by collecting bigram counts for words in W\n",
    "m1_list= []\n",
    "for i in range(0, len(w)):\n",
    "    row = []\n",
    "    for j in range(0, len(w)):\n",
    "        row.append(bigrams_freq[(w[i], w[j])])\n",
    "    m1_list.append(row)\n",
    "m1 = np.array(m1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram = ngrams(brown.words(), 1)\n",
    "unigram_freq = Counter(unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "734274"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_unigram = sum([fdist[x] for x in w])\n",
    "sum_bigram = 0\n",
    "for x,y in bigrams_freq.keys():\n",
    "    if x in w and y in w:\n",
    "        sum_bigram += bigrams_freq[(x,y)]\n",
    "sum_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute positive pointwise mutual information on M1. Denote this model as M1+\n",
    "# https://stackoverflow.com/questions/22118350/python-sentiment-analysis-using-pointwise-mutual-information\n",
    "import math\n",
    "def ppmi(w1, w2):\n",
    "    p12 = bigrams_freq[(w1, w2)] / float(sum_bigram)\n",
    "    if p12 == 0:\n",
    "        return 0\n",
    "    p1 = fdist[w1] / float(sum_unigram)\n",
    "    p2 = fdist[w2] / float(sum_unigram)\n",
    "    return max(0, math.log(p12/float(p1*p2),2))\n",
    "\n",
    "m1plus_list = []\n",
    "for i in range(0, len(w)):\n",
    "    row = []\n",
    "    for j in range(0, len(w)):\n",
    "        ans = ppmi(w[i], w[j])\n",
    "        row.append(ans)\n",
    "    m1plus_list.append(row)\n",
    "m1plus = np.array(m1plus_list)\n",
    "m1plus\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a latent semantic model (denoted by M2) by applying PCA to M1+\n",
    "from sklearn.decomposition import PCA\n",
    "def m2_pca(dimension):\n",
    "    pca = PCA(n_components=dimension)\n",
    "    return np.array(pca.fit_transform(m1plus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_10 = m2_pca(10)\n",
    "m2_100 = m2_pca(100)\n",
    "m2_300 = m2_pca(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index for each word of rg65 in w\n",
    "rg65_id = {}\n",
    "for i in range(0, len(rg65)):\n",
    "    for j in range(0,len(w)):\n",
    "        if w[j] == rg65[i]:\n",
    "            rg65_id[rg65[i]] = j\n",
    "            break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Pearson correlation between cosine similarities of model and human similarities\n",
    "# from scipy.spatial import distance\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "def pearson_cos_human(model):\n",
    "    cos_sim = []\n",
    "    for i in range(0, 65):\n",
    "        cos_sim.append(distance.cosine(model[rg65_id[rg65[i+i]]], model[rg65_id[rg65[i+i+1]]]))\n",
    "    return stats.pearsonr(cos_sim, human_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mengzelev\\anaconda3\\envs\\csc2611\\lib\\site-packages\\scipy\\spatial\\distance.py:699: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.05494857263247904, 0.6637493854323102)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_cos_human(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.004076917338954211, 0.9742874268562585)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_cos_human(m1plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.19090287460604605, 0.1276857414248603)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_cos_human(m2_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.2944823527803687, 0.017256845325594353)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_cos_human(m2_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.2849201640946526, 0.021423615545674284)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_cos_human(m2_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"plays\" in w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get common test case\n",
    "test = []\n",
    "with open(\"tests/word-test-v1.txt\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        words = line.split(\" \")\n",
    "        if len(words) == 4 and words[0] in w and words[1] in w and words[2] in w and words[3] in w:\n",
    "            test.append(line)\n",
    "\n",
    "with open(\"tests/word-test-common.txt\", mode=\"w+\") as f:\n",
    "    for line in test:\n",
    "        f.write(line + '\\n')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_id(word):\n",
    "    for i, ww in enumerate(w):\n",
    "        if ww == word:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "tree = spatial.KDTree(m2_300)\n",
    "def analogical_reasoning(wa1, wa2, wb1):\n",
    "    b2 = m2_300[find_id(wb1)] - m2_300[find_id(wa1)] + m2_300[find_id(wa2)]\n",
    "    return w[tree.query(b2)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy_test_accuracy(file):\n",
    "    correct, total = 0, 0\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            total += 1\n",
    "            words = line.strip().split(\" \")\n",
    "            res = analogical_reasoning(words[0], words[1], words[2])\n",
    "            if(res == words[3]):\n",
    "                correct += 1\n",
    "    return correct/float(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analogy_test_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Mengzelev\\OneDrive - University of Toronto\\Documents\\UofT\\courses\\CSC2611\\Assignment\\CSC2611-Assignment\\exercise.ipynb Cell 26'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Mengzelev/OneDrive%20-%20University%20of%20Toronto/Documents/UofT/courses/CSC2611/Assignment/CSC2611-Assignment/exercise.ipynb#ch0000025?line=0'>1</a>\u001b[0m analogy_test_accuracy(\u001b[39m\"\u001b[39m\u001b[39mtests\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mword-test-semantic.txt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'analogy_test_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "analogy_test_accuracy(\"tests\\word-test-semantic.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001004016064257028"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy_test_accuracy(\"tests\\word-test-syntactic.txt\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e39bb4bc0dd09b8d636f7de561eaa609baf178136a5651a1bfee988d4f249979"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('csc2611': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
